## Status: ‚úÖ Rebuilt

# Automation Checklist (Current Stack)

This checklist tracks the status and verification of automated tasks and key service integrations within the **current `automation-stack` and `freqtrade` devcontainer architecture.** It should be maintained by an AI agent or developers.

**Legend:**
*   `[ ]` - Pending / To Be Verified
*   `[‚úÖ]` - Verified / Completed Successfully
*   `[‚ùå]` - Failed / Error / Issue Noted
*   `[üöß]` - In Progress / Under Development
*   `[N/A]` - Not Applicable (for current baseline)

---

## I. Core Service Verification (`automation-stack`)

Ensure all services in `docker-compose.yml` are operational and accessible as expected.

*   **Traefik Reverse Proxy:**
    *   `[‚úÖ]` Traefik dashboard accessible (if exposed, typically `http://localhost:8080/dashboard/` or `http://traefik.localhost/dashboard/`).
    *   `[‚úÖ]` Services (n8n, Controller) routed correctly via Traefik host rules (e.g., `http://n8n.localhost`, `http://controller.localhost`).
*   **OpenWebUI (`openwebui_auto`):**
    *   `[‚úÖ]` Web interface accessible (e.g., `http://localhost:3000` verified; `http://openwebui.localhost` verified).
    *   `[üöß]` User registration and login functional. **Note:** Requires manual browser verification; page loads, auth enabled.
    *   `[‚úÖ]` Able to connect to Ollama service (`ollama_auto`).
    *   `[‚úÖ]` Able to pull and run a model from Ollama (e.g., `llama3`). **Note:** `llama3` pull successful. Running model verified by basic chat test.
    *   `[‚úÖ]` Basic chat with a local model works.
    *   `[‚úÖ]` Can connect to OpenRouter via the proxy service.
    *   `[‚úÖ]` Basic chat with an OpenRouter model (via proxy) works.
*   **Ollama (`ollama_auto`):**
    *   `[ ]` Service logs indicate successful startup and GPU detection (if applicable).
    *   `[ ]` API accessible within Docker network (e.g., from OpenWebUI or n8n at `http://ollama_auto:11434`).
    *   `[ ]` Models can be pulled via OpenWebUI or `docker exec ollama_auto ollama pull <model_name>`.
*   **n8n (`n8n_auto`):**
    *   `[‚úÖ]` Web interface accessible (e.g., `http://localhost:5678` or `http://n8n.localhost`).
    *   `[ ]` Basic workflow creation and execution functional.
    *   `[ ]` HTTP Request node can reach other services on `auto-stack-net` (e.g., Controller).
    *   `[ ]` Access to shared volumes (e.g., `/host_vault/automation_docs`, `/host_vault/freqtrade_docs`) verified if configured and used by workflows.
*   **FastAPI Controller (`controller_auto`):**
    *   `[‚úÖ]` Service logs indicate successful startup.
    *   `[‚úÖ]` API accessible via Traefik (e.g., `http://controller.localhost/status`) and directly on `auto-stack-net` (e.g. `http://controller_auto:5050/status`).
    *   `[‚úÖ]` `/docs` endpoint (OpenAPI spec) is accessible and shows defined routes.
    *   `[‚úÖ]` Key API endpoints (e.g., health check, example command) respond correctly. (Note: `/status` and `/notify` confirmed).
*   **OpenRouter Proxy (`openrouter_proxy_auto`) (Optional):**
    *   `[‚úÖ]` Service logs indicate successful startup (includes `OPENROUTER_API_KEY` check).
    *   `[‚úÖ]` API accessible via Traefik (e.g., `http://openrouter-proxy.localhost/v1/...`).
    *   `[‚úÖ]` `/healthz` endpoint accessible and returns `OK`.
    *   `[‚úÖ]` Basic proxy functionality verified.
    *   `[‚úÖ]` OpenWebUI can connect to this proxy and use models (e.g., `deepseek/deepseek-prover-v2:free`).
*   **`freq-chat` (Vercel AI Chatbot - Local Development)**:
    *   `[üöß]` Web interface accessible at `http://localhost:3000`. **Note:** UI is rendering but has some visual/styling issues ("wonky UI"). Dev server starts successfully after `package.json` merge and `pnpm install --shamefully-hoist`.
    *   `[‚úÖ]` PostgreSQL database (`freqchat_db`) setup locally on D: drive (via tablespace) with user `freqchat_user`.
    *   `[‚úÖ]` Database schema migrations appear successful (tables exist, `drizzle-kit generate` reports no changes).
    *   `[‚ùå]` TypeScript errors present in VS Code ("Cannot find module", "Cannot find name 'process'"). *Next Action: Restart TS Server / Investigate `tsconfig.json` / Install missing `@types/*`.*
    *   `[üöß]` NextAuth.js `headers()`/`cookies()` warnings in `/api/auth/guest` route. *Next Action: Lower priority, revisit after UI/TS issues.*
    *   `[ ]` API accessible within Docker network (e.g., from n8n at `http://freq-chat:3000` if containerized and named `freq-chat`). *(Assuming local dev for now, not containerized `vercel_chat_auto`)*
    *   `[ ]` Connection to backend LLM providers (e.g., OpenRouter via proxy or direct) from `freq-chat` local dev server.
    *   `[ ]` Integration with self-hosted Mem0 service (`mem0_auto`) for conversational memory.
*   **Mem0 (`mem0_auto`):**
    *   `[ ]` Service (`mem0_auto`) is running (check `docker ps`).
    *   `[ ]` Logs (`docker logs mem0_auto`) indicate successful startup, connection to Qdrant, and readiness to use OpenRouter proxy.
    *   `[ ]` Health check endpoint (`http://${MEM0_HOST:-mem0.localhost}:${MEM0_HOST_PORT:-7860}/status` or Traefik route) returns healthy status.
    *   `[ ]` Basic memory operations (add, search via REST API) are functional.
    *   `[ ]` Data persistence for Mem0 history DB (e.g., `/data/mem0_history.db` in `mem0_data_auto` volume) verified across restarts.
    *   `[ ]` `mem0/server/config.yaml` correctly configured for Qdrant, OpenRouter proxy (via "openai" provider and env vars).
*   **Qdrant (`qdrant_auto`):**
    *   `[ ]` Service (`qdrant_auto`) is running.
    *   `[ ]` Logs (`docker logs qdrant_auto`) are clean.
    *   `[ ]` Qdrant UI/API accessible (e.g., `http://localhost:6333`).
    *   `[ ]` Data persistence for Qdrant vectors (`qdrant_data_auto` volume) verified across restarts.
    *   `[ ]` Mem0 service successfully connects to Qdrant.
*   **PostgreSQL Logging (`postgres_logging_auto`):**
    *   `[‚úÖ]` Service (`postgres_logging_auto`) is running.
    *   `[‚úÖ]` Logs (`docker logs postgres_logging_auto`) are clean.
    *   `[‚úÖ]` Can connect via `psql` or DB client using credentials from `.env`.
    *   `[‚úÖ]` `agent_logs` table exists with the correct schema.
    *   `[‚úÖ]` `mem0_memory_events` table exists with the correct schema.
    *   `[‚úÖ]` Data persistence for logs (`pgdata_logging_auto` volume) verified.

## II. Freqtrade Dev Container Verification

Ensure the Freqtrade dev container is operational.

*   **Freqtrade Dev Container (`freqtrade_devcontainer`):**
    *   `[ ]` Container starts successfully via VS Code "Reopen in Container" or `docker compose up`.
    *   `[ ]` Freqtrade UI accessible (typically port `8080` forwarded to host, e.g., `http://localhost:8080`).
    *   `[ ]` Freqtrade REST API accessible (e.g., `http://localhost:8080/api/v1/ping`).
    *   `[ ]` `user_data` correctly mounted and accessible within the container.
    *   `[ ]` Basic Freqtrade commands work in the container's terminal (e.g., `freqtrade --version`, `freqtrade list-strategies`).
    *   `[ ]` (If applicable) Devcontainer connected to `auto-stack-net` or relevant shared Docker network for API access from `automation-stack`.

## III. Cross-Stack Integration Verification

Verify communication and workflows between the `automation-stack` and `freqtrade`.

*   **n8n -> Controller API:**
    *   `[ ]` n8n workflow can successfully call a FastAPI Controller endpoint (e.g., to request an action).
*   **Controller -> Freqtrade API:**
    *   `[ ]` Controller (via one of its API endpoints) can successfully call the Freqtrade API (e.g., to get status, list trades, or trigger a backtest).
        *   `[ ]` Authentication to Freqtrade API (JWT) is handled correctly by the controller.
*   **n8n -> OpenRouter Proxy (LLM Tasks):**
    *   `[ ]` n8n workflow (using HTTP Request node) can successfully call `http://openrouter-proxy.localhost/v1/chat/completions` and receive a response from an OpenRouter model.
*   **n8n -> Vercel AI Chat/Ollama (LLM Tasks):**
    *   `[ ]` n8n workflow can send a prompt to Vercel AI Chat's OpenAI-compatible API (`http://vercel_chat_auto:8080/v1/chat/completions`) and receive a response from a local Ollama model.
*   **Controller -> Mem0 API:**
    *   `[ ]` Controller can successfully call self-hosted Mem0 REST API endpoints (add, search).
*   **n8n -> Mem0 API:**
    *   `[ ]` n8n workflow can successfully call self-hosted Mem0 REST API endpoints.
*   **`freq-chat` -> Mem0 API:**
    *   `[ ]` `freq-chat` backend can successfully call self-hosted Mem0 REST API for conversational memory.
*   **Shared Documentation Access:**
    *   `[ ]` n8n can access/read files from mounted doc volumes (e.g., `/host_vault/automation_docs/`) if a workflow requires it.
    *   `[ ]` (Conceptual) Controller can access/read files from relevant workspace directories if its function requires it.
*   **Multi-Agent Orchestration Workflows:**
    *   `[ ]` CentralBrain_Agent, manager agents (FreqtradeManager, FreqAIManager, ResearchManager, UtilityManager), and sub-agents are present, correctly configured, and able to trigger/aggregate via HTTP webhooks. See CentralBrain.md and n8nChat_prompt_templates.md.
*   **FastAPI Controller/n8n Integration:**
    *   `[ ]` n8n workflow can trigger and be triggered by the FastAPI Controller using /execute and /notify endpoints (see webhookFlows.md for step-by-step guide).

## IV. Example Automation Tasks (Conceptual - To Be Developed/Verified)

These are potential automation tasks an AI agent or n8n workflows might perform.

*   **Automated Backtesting & Reporting:**
    *   `[ ]` **Trigger:** Manual via Controller endpoint, or scheduled in n8n.
    *   `[ ]` **Action:**
        1.  n8n/Controller calls Freqtrade API to start a backtest with a specified strategy/config.
        2.  Monitor backtest completion (e.g., polling Freqtrade API or checking for output files).
        3.  Fetch backtest results (JSON/CSV).
        4.  (Optional) Send results to an LLM via OpenRouter Proxy for summarization/analysis.
        5.  Generate a report (e.g., Markdown, PDF) and notify user (e.g., Discord, email).
    *   **Status:** `[ ]` (Not Implemented / To Be Designed)
*   **Documentation Sync/Validation (Git-based - Optional Advanced):**
    *   `[ ]` **Trigger:** Scheduled in n8n.
    *   `[ ]` **Action:** (If using git-based doc sync as per `n8n_doc_mirror_update.md`)
        1.  n8n executes `git pull` in specified local documentation repositories (requires `N8N_ALLOW_EXEC` and volume mounts).
        2.  (Optional) Validate links or format of updated docs.
        3.  Notify on success/failure.
    *   **Status:** `[ ]` (Optional Feature - Requires specific setup)
*   **Strategy Parameter Update via LLM Suggestion:**
    *   `[üöß]` **Trigger:** Manual request to AI agent.
    *   `[üöß]` **Action:**
        1.  User provides context (current strategy, market conditions).
        2.  AI agent queries LLM (via Vercel AI Chat) for suggestions on parameter adjustments.
        3.  Agent presents suggestions to user for approval.
        4.  (If approved) Agent uses Controller API to update strategy file or relevant config.
        5.  (Optional) Trigger a backtest with new parameters.
    *   **Status:** `[üöß]` (Conceptual / High Complexity)
*   **System Health Monitoring:**
    *   `[ ]` **Trigger:** Scheduled in n8n.
    *   `[ ]` **Action:**
        1.  n8n calls health/status endpoints of key services (Controller, Freqtrade API, OpenRouter Proxy ping).
        2.  Check for expected responses.
        3.  Notify admin/user if any service is unresponsive or reports errors.
    *   **Status:** `[ ]` (To Be Designed)
*   **Multi-Agent Documentation Processing:**
    *   `[ ]` **Trigger:** Manual or scheduled via CentralBrain_Agent workflow.
    *   `[ ]` **Action:** CentralBrain_Agent dispatches documentation processing to DocAgent(s), aggregates results, and stores summaries in the central doc database.
    *   `[ ]` **Status:** `[ ]` (Conceptual / To Be Implemented)

## V. n8n AI Capabilities & n8nChat Integration

Verify n8n's AI features, including n8nChat and MCP nodes, and their integration with the `openrouter_proxy_auto`.

*   **n8nChat Extension:**
    *   `[ ]` n8nChat browser extension installed and connected to `http://n8n.localhost`.
    *   `[ ]` n8nChat configured to use `http://openrouter-proxy.localhost/v1` as its LLM endpoint.
    *   `[ ]` n8nChat can successfully generate a basic workflow (e.g., "When webhook is called, respond with 'Hello World'") using the proxy for any LLM interactions.
    *   `[ ]` n8nChat can modify an existing workflow using the proxy.
*   **n8n MCP (Model Control Protocol) Nodes:**
    *   `[ ]` **MCP Client Node:**
        *   `[ ]` An n8n workflow using the "MCP Client" node can successfully call `http://openrouter-proxy.localhost/v1/chat/completions` (if node supports OpenAI compatibility directly or via a generic HTTP call).
        *   `[ ]` The workflow receives and processes the LLM response correctly.
    *   `[ ]` **MCP Server Trigger Node:**
        *   `[ ]` An n8n workflow is created with an "MCP Server Trigger" node (e.g., exposing a simple tool that returns current date/time).
        *   `[ ]` The MCP Server Trigger's webhook URL is accessible (e.g., `http://n8n.localhost/webhook/<your-mcp-path>`).
        *   `[ ]` The exposed tool can be successfully called (e.g., using `curl` or another HTTP client), and it returns the expected data.

## VI. Agent-Specific Tasks & Capabilities Verification

*   **Code Generation/Modification (via Controller):**
    *   `[ ]` Agent can request the Controller to read a specified file from the workspace.
    *   `[ ]` Agent can propose changes to a file, and the Controller can (after user approval if configured) apply those changes.
    *   `[ ]` Controller has safeguards against overwriting critical files or applying malicious code.
*   **Information Retrieval (from Docs/Workspace):**
    *   `[ ]` Agent can request the Controller to search for information within mounted documentation or workspace files.
*   **n8n Workflow Management (Conceptual):**
    *   `[ ]` Agent can request the Controller to list available n8n workflows (via n8n API).
    *   `[ ]` Agent can request the Controller to trigger a specific n8n workflow (via n8n API webhook).
    *   `[ ]` (Advanced) Agent can propose JSON for a new/updated n8n workflow, and Controller can deploy it via n8n API.

## VII. Unified Logging

*   **Unified Logging (PostgreSQL):**
    *   `[‚úÖ]` Services (e.g., n8n workflows) can write to the `agent_logs` table in the `postgres_logging_auto` database.
    *   `[‚úÖ]` Log entries are correctly formatted and queryable (verified for `n8n_workflow_UnifiedLogging.json`).
    *   `[ ]` **Next n8n Workflow:** Configure and test `n8n_workflow_Mem0_Memory_Logger.json` for writing to `mem0_memory_events`.
    *   `[‚úÖ]` Schema matches `docs/guides/mem0_server_guide.md` (which references `UnifiedLogging.md` concepts).

## I. Cross-Stack Integration Validation (Goal 1)

*   `[ ]` Verify bi-directional API communication between Freqtrade and automation-stack (n8n, FastAPI Controller) using real test workflows (see MasterGameplan.md).
*   `[ ]` Document all integration points and update troubleshooting guides with any new findings.
*   `[ ]` Confirm that all endpoints are reachable and authenticated as required.
*   `[ ]` Capture and resolve any integration errors or edge cases.

---

**Notes & Next Steps:**
*   This checklist is a living document and should be updated as the system evolves.
*   Prioritize verifying core service functionality and inter-service communication first.
*   Develop and verify specific automation workflows based on project needs.
